# ğŸ”§ ê¸°ìˆ  ëª…ì„¸ì„œ - TensorFlow.js í•„ê¸° ì¸ì‹ ì‹œìŠ¤í…œ

## ğŸ“‹ ì‹œìŠ¤í…œ ê°œìš”

### ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜
```
Input Layer (ìº”ë²„ìŠ¤) â†’ ì „ì²˜ë¦¬ â†’ ë¶„í•  â†’ ì¸ì‹ â†’ ì¶œë ¥
     â†“              â†“        â†“      â†“      â†“
DrawingCanvas â†’ Preprocessing â†’ Segmentation â†’ Recognition â†’ UI Display
```

### í•µì‹¬ ìš”êµ¬ì‚¬í•­
- **ìº”ë²„ìŠ¤ í¬ê¸°**: 200x60px (êµê³¼ì„œ ë‹µì•ˆë€ ìµœì í™”)
- **ì¸ì‹ ëŒ€ìƒ**: ì—°ì†ëœ ìˆ«ì '43525' 
- **ì •í™•ë„**: 85-90% (ì´ˆë“±í•™ìƒ í•„ê¸° ê¸°ì¤€)
- **ì‘ë‹µ ì‹œê°„**: <500ms
- **ë™ì‘ ëª¨ë“œ**: ì™„ì „ ì˜¤í”„ë¼ì¸

## ğŸ¨ DrawingCanvas ì»´í¬ë„ŒíŠ¸

### ì¸í„°í˜ì´ìŠ¤ ëª…ì„¸
```typescript
interface DrawingCanvasProps {
  width: 200;
  height: 60;
  lineWidth: 2 | 3;
  backgroundColor: '#000000';
  strokeColor: '#ffffff';
  onDrawingComplete?: (imageData: ImageData) => void;
  onClear?: () => void;
}

interface DrawingCanvasRef {
  clearCanvas(): void;
  getImageData(): ImageData;
  undo(): void;
  isEmpty(): boolean;
}
```

### ì´ë²¤íŠ¸ ì²˜ë¦¬
```typescript
// ë§ˆìš°ìŠ¤ ì´ë²¤íŠ¸
onMouseDown(e: MouseEvent): void
onMouseMove(e: MouseEvent): void  
onMouseUp(e: MouseEvent): void

// í„°ì¹˜ ì´ë²¤íŠ¸
onTouchStart(e: TouchEvent): void
onTouchMove(e: TouchEvent): void
onTouchEnd(e: TouchEvent): void

// ì¢Œí‘œ ì •ê·œí™”
normalizeCoordinates(clientX: number, clientY: number): Point
```

### ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­
- **ë“œë¡œì‰ ì§€ì—°**: <16ms (60fps ìœ ì§€)
- **ë©”ëª¨ë¦¬ ì‚¬ìš©**: <10MB
- **í„°ì¹˜ ì •í™•ë„**: Â±2px

## ğŸ–¼ï¸ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹œìŠ¤í…œ

### ImagePreprocessor í´ë˜ìŠ¤
```typescript
class ImagePreprocessor {
  // ì£¼ìš” ë©”ì„œë“œ
  extractImageData(canvas: HTMLCanvasElement): ImageData
  convertToGrayscale(imageData: ImageData): Uint8Array
  binarizeImage(grayscale: Uint8Array, threshold: number): Uint8Array
  removeNoise(binary: Uint8Array, width: number, height: number): Uint8Array
  normalizeToMNIST(image: Uint8Array, width: number, height: number): Float32Array
}
```

### ì•Œê³ ë¦¬ì¦˜ ìƒì„¸

#### 1. ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
```typescript
// ê³µì‹: Y = 0.299*R + 0.587*G + 0.114*B
function convertToGrayscale(imageData: ImageData): Uint8Array {
  const { data, width, height } = imageData;
  const grayscale = new Uint8Array(width * height);
  
  for (let i = 0; i < data.length; i += 4) {
    const gray = Math.round(
      data[i] * 0.299 +     // R
      data[i + 1] * 0.587 + // G
      data[i + 2] * 0.114   // B
    );
    grayscale[i / 4] = gray;
  }
  
  return grayscale;
}
```

#### 2. ì´ì§„í™” ì²˜ë¦¬
```typescript
function binarizeImage(grayscale: Uint8Array, threshold: number = 128): Uint8Array {
  return grayscale.map(pixel => pixel > threshold ? 255 : 0);
}
```

#### 3. ë…¸ì´ì¦ˆ ì œê±°
```typescript
// ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ + ëª¨í´ë¡œì§€ ì—°ì‚°
function removeNoise(binary: Uint8Array, width: number, height: number): Uint8Array {
  // 1. ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ ì ìš©
  const blurred = applyGaussianBlur(binary, width, height, 1.0);
  
  // 2. ëª¨í´ë¡œì§€ ì¹¨ì‹ â†’ íŒ½ì°½
  const eroded = morphologyErode(blurred, width, height, 1);
  const dilated = morphologyDilate(eroded, width, height, 1);
  
  return dilated;
}
```

#### 4. MNIST ì •ê·œí™”
```typescript
function normalizeToMNIST(image: Uint8Array, width: number, height: number): Float32Array {
  // 1. ê²½ê³„ ë°•ìŠ¤ ê³„ì‚°
  const bbox = calculateBoundingBox(image, width, height);
  
  // 2. í¬ë¡­ ë° ë¦¬ì‚¬ì´ì¦ˆ
  const cropped = cropImage(image, bbox, width, height);
  const resized = resizeImage(cropped, bbox.width, bbox.height, 28, 28);
  
  // 3. ì¤‘ì•™ ì •ë ¬
  const centered = centerImage(resized, 28, 28);
  
  // 4. í”½ì…€ ê°’ ì •ê·œí™” (0-1 ë²”ìœ„)
  return new Float32Array(centered.map(pixel => pixel / 255.0));
}
```

## âœ‚ï¸ ìˆ«ì ë¶„í•  ì‹œìŠ¤í…œ

### DigitSegmenter í´ë˜ìŠ¤
```typescript
class DigitSegmenter {
  // ì£¼ìš” ë©”ì„œë“œ
  segmentDigits(image: Uint8Array, width: number, height: number): DigitSegment[]
  calculateVerticalProjection(image: Uint8Array, width: number, height: number): number[]
  findSegmentationPoints(projection: number[]): number[]
  extractConnectedComponents(image: Uint8Array, width: number, height: number): Component[]
}

interface DigitSegment {
  x: number;
  y: number;
  width: number;
  height: number;
  imageData: Uint8Array;
  confidence: number;
}
```

### ìˆ˜ì§ íˆ¬ì˜ ì•Œê³ ë¦¬ì¦˜
```typescript
function calculateVerticalProjection(image: Uint8Array, width: number, height: number): number[] {
  const projection = new Array(width).fill(0);
  
  for (let x = 0; x < width; x++) {
    for (let y = 0; y < height; y++) {
      const index = y * width + x;
      if (image[index] > 0) {
        projection[x]++;
      }
    }
  }
  
  return projection;
}
```

### ë¶„í•  ì  ì°¾ê¸°
```typescript
function findSegmentationPoints(projection: number[]): number[] {
  const points: number[] = [];
  const threshold = Math.max(...projection) * 0.1; // 10% ì„ê³„ê°’
  
  for (let i = 1; i < projection.length - 1; i++) {
    if (projection[i] < threshold && 
        projection[i-1] >= threshold && 
        projection[i+1] >= threshold) {
      points.push(i);
    }
  }
  
  return points;
}
```

### ì—°ê²° ìš”ì†Œ ë¶„ì„
```typescript
function extractConnectedComponents(image: Uint8Array, width: number, height: number): Component[] {
  const visited = new Array(width * height).fill(false);
  const components: Component[] = [];
  
  for (let y = 0; y < height; y++) {
    for (let x = 0; x < width; x++) {
      const index = y * width + x;
      if (image[index] > 0 && !visited[index]) {
        const component = floodFill(image, visited, x, y, width, height);
        if (component.size > 50) { // ë…¸ì´ì¦ˆ ì œê±°
          components.push(component);
        }
      }
    }
  }
  
  return components;
}
```

## ğŸ§  TensorFlow.js ëª¨ë¸ ì‹œìŠ¤í…œ

### DigitRecognizer í´ë˜ìŠ¤
```typescript
class DigitRecognizer {
  private model: tf.LayersModel;
  
  async loadModel(modelPath: string): Promise<void>
  async predict(imageData: Float32Array): Promise<PredictionResult>
  async predictBatch(images: Float32Array[]): Promise<PredictionResult[]>
  dispose(): void
}

interface PredictionResult {
  digit: number;
  confidence: number;
  probabilities: number[]; // 0-9 ê° ìˆ«ìë³„ í™•ë¥ 
}
```

### ëª¨ë¸ êµ¬ì¡°
```typescript
// CNN ëª¨ë¸ êµ¬ì¡°
const model = tf.sequential({
  layers: [
    tf.layers.conv2d({
      inputShape: [28, 28, 1],
      filters: 32,
      kernelSize: 3,
      activation: 'relu'
    }),
    tf.layers.maxPooling2d({ poolSize: [2, 2] }),
    tf.layers.conv2d({
      filters: 64,
      kernelSize: 3,
      activation: 'relu'
    }),
    tf.layers.maxPooling2d({ poolSize: [2, 2] }),
    tf.layers.flatten(),
    tf.layers.dense({
      units: 128,
      activation: 'relu'
    }),
    tf.layers.dropout({ rate: 0.5 }),
    tf.layers.dense({
      units: 10,
      activation: 'softmax'
    })
  ]
});
```

### ì˜ˆì¸¡ ì²˜ë¦¬
```typescript
async function predict(imageData: Float32Array): Promise<PredictionResult> {
  // 1. í…ì„œ ìƒì„±
  const tensor = tf.tensor4d(imageData, [1, 28, 28, 1]);
  
  // 2. ëª¨ë¸ ì˜ˆì¸¡
  const prediction = this.model.predict(tensor) as tf.Tensor;
  const probabilities = await prediction.data();
  
  // 3. ê²°ê³¼ ì²˜ë¦¬
  const maxIndex = probabilities.indexOf(Math.max(...probabilities));
  const confidence = probabilities[maxIndex];
  
  // 4. ë©”ëª¨ë¦¬ ì •ë¦¬
  tensor.dispose();
  prediction.dispose();
  
  return {
    digit: maxIndex,
    confidence: confidence,
    probabilities: Array.from(probabilities)
  };
}
```

## ğŸ¯ ë©”ì¸ í†µí•© ì‹œìŠ¤í…œ

### HandwritingRecognizer í´ë˜ìŠ¤
```typescript
class HandwritingRecognizer {
  private preprocessor: ImagePreprocessor;
  private segmenter: DigitSegmenter;
  private recognizer: DigitRecognizer;
  
  async recognize(canvas: HTMLCanvasElement): Promise<RecognitionResult>
  async recognizeSequence(canvas: HTMLCanvasElement): Promise<SequenceResult>
  dispose(): void
}

interface RecognitionResult {
  success: boolean;
  digits: number[];
  confidence: number;
  processingTime: number;
  intermediateResults: {
    preprocessed: ImageData;
    segments: DigitSegment[];
    predictions: PredictionResult[];
  };
}
```

### ì „ì²´ íŒŒì´í”„ë¼ì¸
```typescript
async function recognize(canvas: HTMLCanvasElement): Promise<RecognitionResult> {
  const startTime = performance.now();
  
  try {
    // 1. ì´ë¯¸ì§€ ì „ì²˜ë¦¬
    const imageData = canvas.getContext('2d')!.getImageData(0, 0, 200, 60);
    const preprocessed = this.preprocessor.processImage(imageData);
    
    // 2. ìˆ«ì ë¶„í• 
    const segments = this.segmenter.segmentDigits(
      preprocessed.binary, 
      preprocessed.width, 
      preprocessed.height
    );
    
    // 3. ê° ìˆ«ì ì¸ì‹
    const predictions: PredictionResult[] = [];
    for (const segment of segments) {
      const normalized = this.preprocessor.normalizeToMNIST(
        segment.imageData, 
        segment.width, 
        segment.height
      );
      const prediction = await this.recognizer.predict(normalized);
      predictions.push(prediction);
    }
    
    // 4. ê²°ê³¼ ì¡°í•©
    const digits = predictions.map(p => p.digit);
    const confidence = predictions.reduce((sum, p) => sum + p.confidence, 0) / predictions.length;
    
    return {
      success: true,
      digits,
      confidence,
      processingTime: performance.now() - startTime,
      intermediateResults: {
        preprocessed: preprocessed.imageData,
        segments,
        predictions
      }
    };
    
  } catch (error) {
    return {
      success: false,
      digits: [],
      confidence: 0,
      processingTime: performance.now() - startTime,
      intermediateResults: null
    };
  }
}
```

## ğŸ¨ UI ì»´í¬ë„ŒíŠ¸

### RecognitionResult ì»´í¬ë„ŒíŠ¸
```typescript
interface RecognitionResultProps {
  result: RecognitionResult;
  showDetails?: boolean;
  onRetry?: () => void;
}

function RecognitionResult({ result, showDetails, onRetry }: RecognitionResultProps) {
  return (
    <div className="recognition-result">
      <div className="result-display">
        <span className="digits">{result.digits.join('')}</span>
        <span className="confidence">{(result.confidence * 100).toFixed(1)}%</span>
      </div>
      
      {showDetails && (
        <div className="details">
          <div>ì²˜ë¦¬ ì‹œê°„: {result.processingTime.toFixed(0)}ms</div>
          <div>ê°œë³„ ìˆ«ì: {result.intermediateResults.predictions.map(p => 
            `${p.digit}(${(p.confidence * 100).toFixed(1)}%)`
          ).join(', ')}</div>
        </div>
      )}
      
      {!result.success && (
        <button onClick={onRetry} className="retry-button">
          ë‹¤ì‹œ ì‹œë„
        </button>
      )}
    </div>
  );
}
```

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”

### ë©”ëª¨ë¦¬ ê´€ë¦¬
```typescript
class MemoryManager {
  private tensorCache = new Map<string, tf.Tensor>();
  
  cacheTensor(key: string, tensor: tf.Tensor): void {
    this.disposeTensor(key);
    this.tensorCache.set(key, tensor);
  }
  
  disposeTensor(key: string): void {
    const tensor = this.tensorCache.get(key);
    if (tensor) {
      tensor.dispose();
      this.tensorCache.delete(key);
    }
  }
  
  disposeAll(): void {
    this.tensorCache.forEach(tensor => tensor.dispose());
    this.tensorCache.clear();
  }
}
```

### ì›¹ ì›Œì»¤ í™œìš©
```typescript
// worker.ts
self.onmessage = async (e: MessageEvent) => {
  const { type, data } = e.data;
  
  switch (type) {
    case 'preprocess':
      const preprocessed = await preprocessImage(data.imageData);
      self.postMessage({ type: 'preprocessed', result: preprocessed });
      break;
      
    case 'segment':
      const segments = await segmentDigits(data.image);
      self.postMessage({ type: 'segmented', result: segments });
      break;
  }
};
```

## ğŸ” ë””ë²„ê¹… ë° ëª¨ë‹ˆí„°ë§

### ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
```typescript
class PerformanceMonitor {
  private metrics: PerformanceMetric[] = [];
  
  startTimer(name: string): string {
    const id = `${name}-${Date.now()}`;
    this.metrics.push({
      id,
      name,
      startTime: performance.now(),
      endTime: null
    });
    return id;
  }
  
  endTimer(id: string): number {
    const metric = this.metrics.find(m => m.id === id);
    if (metric) {
      metric.endTime = performance.now();
      return metric.endTime - metric.startTime;
    }
    return 0;
  }
  
  getAverageTime(name: string): number {
    const completed = this.metrics.filter(m => m.name === name && m.endTime);
    if (completed.length === 0) return 0;
    
    const total = completed.reduce((sum, m) => sum + (m.endTime! - m.startTime), 0);
    return total / completed.length;
  }
}
```

### ì—ëŸ¬ ì²˜ë¦¬
```typescript
class ErrorHandler {
  static handleRecognitionError(error: Error): RecognitionResult {
    console.error('Recognition failed:', error);
    
    // ì—ëŸ¬ íƒ€ì…ë³„ ì²˜ë¦¬
    if (error.name === 'ModelLoadError') {
      return {
        success: false,
        digits: [],
        confidence: 0,
        processingTime: 0,
        error: 'ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•´ì£¼ì„¸ìš”.'
      };
    }
    
    if (error.name === 'MemoryError') {
      return {
        success: false,
        digits: [],
        confidence: 0,
        processingTime: 0,
        error: 'ë©”ëª¨ë¦¬ ë¶€ì¡±. ìº”ë²„ìŠ¤ë¥¼ ì§€ìš°ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'
      };
    }
    
    return {
      success: false,
      digits: [],
      confidence: 0,
      processingTime: 0,
      error: 'ì¸ì‹ ì‹¤íŒ¨. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'
    };
  }
}
```

## ğŸ§ª í…ŒìŠ¤íŠ¸ ëª…ì„¸

### ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
```typescript
describe('ImagePreprocessor', () => {
  it('should convert image to grayscale correctly', () => {
    const mockImageData = createMockImageData(100, 100);
    const result = preprocessor.convertToGrayscale(mockImageData);
    expect(result.length).toBe(10000);
    expect(result[0]).toBeGreaterThanOrEqual(0);
    expect(result[0]).toBeLessThanOrEqual(255);
  });
  
  it('should normalize image to MNIST format', () => {
    const mockImage = new Uint8Array(100 * 100);
    const result = preprocessor.normalizeToMNIST(mockImage, 100, 100);
    expect(result.length).toBe(28 * 28);
    expect(result[0]).toBeGreaterThanOrEqual(0);
    expect(result[0]).toBeLessThanOrEqual(1);
  });
});
```

### í†µí•© í…ŒìŠ¤íŠ¸
```typescript
describe('HandwritingRecognizer Integration', () => {
  it('should recognize single digit correctly', async () => {
    const canvas = createMockCanvas('5');
    const result = await recognizer.recognize(canvas);
    
    expect(result.success).toBe(true);
    expect(result.digits).toEqual([5]);
    expect(result.confidence).toBeGreaterThan(0.8);
    expect(result.processingTime).toBeLessThan(500);
  });
  
  it('should recognize sequence "43525" correctly', async () => {
    const canvas = createMockCanvas('43525');
    const result = await recognizer.recognize(canvas);
    
    expect(result.success).toBe(true);
    expect(result.digits).toEqual([4, 3, 5, 2, 5]);
    expect(result.confidence).toBeGreaterThan(0.85);
  });
});
```

## ğŸ“ˆ ë°°í¬ ë° ìš´ì˜

### ë¹Œë“œ ìµœì í™”
```typescript
// webpack.config.js
module.exports = {
  resolve: {
    alias: {
      '@tensorflow/tfjs$': '@tensorflow/tfjs/dist/tf.min.js'
    }
  },
  optimization: {
    splitChunks: {
      cacheGroups: {
        tensorflow: {
          test: /[\\/]node_modules[\\/]@tensorflow[\\/]/,
          name: 'tensorflow',
          chunks: 'all',
          priority: 10
        }
      }
    }
  }
};
```

### ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì§€í‘œ
- **First Contentful Paint**: <1.5ì´ˆ
- **Largest Contentful Paint**: <2.5ì´ˆ
- **Time to Interactive**: <3.5ì´ˆ
- **ì¸ì‹ ì‘ë‹µ ì‹œê°„**: <500ms
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: <100MB

---

**Version**: 1.0.0  
**Updated**: 2025.01.09  
**Status**: TensorFlow.js ê¸°ë°˜ ì•„í‚¤í…ì²˜ ì™„ë£Œ
